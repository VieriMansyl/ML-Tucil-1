{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Allocate training data 80% and test data 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree:\n",
      " |--- worst concave points <= 0.14\n",
      "|   |--- worst area <= 957.45\n",
      "|   |   |--- worst perimeter <= 107.75\n",
      "|   |   |   |--- area error <= 91.56\n",
      "|   |   |   |   |--- area error <= 48.98\n",
      "|   |   |   |   |   |--- mean concavity <= 0.14\n",
      "|   |   |   |   |   |   |--- smoothness error <= 0.00\n",
      "|   |   |   |   |   |   |   |--- worst compactness <= 0.20\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- worst compactness >  0.20\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- smoothness error >  0.00\n",
      "|   |   |   |   |   |   |   |--- worst texture <= 32.83\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- worst texture >  32.83\n",
      "|   |   |   |   |   |   |   |   |--- worst texture <= 33.81\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- worst texture >  33.81\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- mean concavity >  0.14\n",
      "|   |   |   |   |   |   |--- mean texture <= 20.37\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- mean texture >  20.37\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- area error >  48.98\n",
      "|   |   |   |   |   |--- mean symmetry <= 0.17\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- mean symmetry >  0.17\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- area error >  91.56\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- worst perimeter >  107.75\n",
      "|   |   |   |--- mean perimeter <= 91.92\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- mean perimeter >  91.92\n",
      "|   |   |   |   |--- concavity error <= 0.04\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- concavity error >  0.04\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |--- worst area >  957.45\n",
      "|   |   |--- mean symmetry <= 0.15\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- mean symmetry >  0.15\n",
      "|   |   |   |--- class: 0\n",
      "|--- worst concave points >  0.14\n",
      "|   |--- worst area <= 729.55\n",
      "|   |   |--- mean smoothness <= 0.11\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- mean smoothness >  0.11\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- worst area >  729.55\n",
      "|   |   |--- texture error <= 0.43\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- texture error >  0.43\n",
      "|   |   |   |--- worst concavity <= 0.20\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- worst concavity >  0.20\n",
      "|   |   |   |   |--- radius error <= 0.24\n",
      "|   |   |   |   |   |--- mean fractal dimension <= 0.06\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- mean fractal dimension >  0.06\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- radius error >  0.24\n",
      "|   |   |   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# initialize DT classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# export the decision tree in text format\n",
    "r = export_text(clf, feature_names=cancer.feature_names.tolist())\n",
    "\n",
    "# show decision tree\n",
    "print(\"decision tree:\\n\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9122807017543859\n",
      "Precision:  0.9672131147540983\n",
      "Recall:  0.8805970149253731\n",
      "F1:  0.9218749999999999\n",
      "Confusion Matrix:\n",
      " [[45  2]\n",
      " [ 8 59]]\n",
      "Cross Validation Accuracy:\n",
      " [0.89473684 0.87719298 0.9122807  0.89473684 0.92982456 0.89473684\n",
      " 0.89473684 0.94736842 0.9122807  0.89285714]\n",
      "Cross Validation F1:\n",
      " [0.91428571 0.90140845 0.93150685 0.91666667 0.94285714 0.91666667\n",
      " 0.92105263 0.95774648 0.92537313 0.90909091]\n"
     ]
    }
   ],
   "source": [
    "# save model using pickle\n",
    "with open('models/decisionTreeClassifier.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "\n",
    "#  load model using pickle\n",
    "with open('models/decisionTreeClassifier.pkl', 'rb') as file:\n",
    "    clf = pickle.load(file)\n",
    "\n",
    "# predict datasets with model\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# measure model's performance using 10-fold cross validation\n",
    "cv = cross_validate(clf, cancer.data, cancer.target, cv=10, scoring=['accuracy', 'f1'])\n",
    "\n",
    "# show metrics\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1: ', f1)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "# show cross validation metrics\n",
    "print('Cross Validation Accuracy:\\n', cv['test_accuracy'])\n",
    "print('Cross Validation F1:\\n', cv['test_f1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis metrik pada model pembelajaran Decision Tree :<br>\n",
    "lorem ipsum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from id3 import Id3Estimator, export_graphviz\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0 0 0 0 4 4 4 4 4 4 0 0 4 2 0 2 4 1 2 1 0 2 0 4 1 4 4 0 0 1 4 1 0 2 4 0 0\n",
      " 1 0 2 0 4 2 4 0 1 4 0 4 0 2 0 1 4 4 4 4 4 4 1 0 2 4 4 2 4 1 2 1 4 0 2 4 0\n",
      " 1 0 4 4 4 4 2 1 2 4 2 4 0 4 2 1 4 0 0 0 4 4 1 0 4 4 4 4 0 0 1 4 2 0 0 2 0\n",
      " 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# initialize KMeans with 5 clusters with n_init=10\n",
    "kmeans = KMeans(n_clusters=5, n_init=10)\n",
    "\n",
    "# train the model\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# save model using pickle\n",
    "with open('models/kMeans.pkl', 'wb') as file:\n",
    "    pickle.dump(kmeans, file)\n",
    "\n",
    "#  load model using pickle\n",
    "with open('models/kMeans.pkl', 'rb') as file:\n",
    "    kmeans = pickle.load(file)\n",
    "\n",
    "# predict datasets with model\n",
    "predictions = kmeans.predict(X_test)\n",
    "\n",
    "print(\"prediction:\\n\" , predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis metrik pada model pembelajaran K-Means :<br>\n",
    "Karena K-Means model merupakan model pembelajaran Unsupervised, maka hasil prediksi dari K-Means yang merupakan prediksi letak data terhadap cluster-cluster yang terbentuk tidak dapat diukur dengan metrik seperti accuracy, precision, recall, F1, dan confusion matrix yang digunakan hanya untuk mengukur model pembelajaran <strong>Supervised</strong>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - Multi-layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9122807017543859\n",
      "Precision:  0.8701298701298701\n",
      "Recall:  1.0\n",
      "F1:  0.9305555555555556\n",
      "Confusion Matrix:\n",
      " [[37 10]\n",
      " [ 0 67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# initialize MLP classifier\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# save model using pickle\n",
    "with open('models/mlpClassifier.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "\n",
    "#  load model using pickle\n",
    "with open('models/mlpClassifier.pkl', 'rb') as file:\n",
    "    clf = pickle.load(file)\n",
    "\n",
    "# predict datasets with model\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# show metrics\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1: ', f1)\n",
    "print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[60.    1.6 ]\n",
      " [65.    1.7 ]\n",
      " [80.    1.9 ]\n",
      " [75.    1.85]]\n",
      "X_test:\n",
      " [[70.   1.8]\n",
      " [50.   1.4]\n",
      " [55.   1.5]]\n",
      "y_train:\n",
      " [0. 1. 1. 1.]\n",
      "y_test:\n",
      " [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = np.array([[60, 1.6, 0], [55, 1.5, 0], [65, 1.7, 1], [70, 1.8, 1], [80, 1.9, 1], [50, 1.4, 0], [75, 1.85, 1]])\n",
    "\n",
    "# Split the data into input (X) and output (y) variables\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"y_train:\\n\", y_train)\n",
    "print(\"y_test:\\n\", y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0be323afe9d07a94ba04cb788bc101868fc6fddb09804aaa7221b01322140dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
